---
title: "Project 4"
author: "Clara"

output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(keras)

```


```{r}
load("car_clean.RData")
#complete cases without source, severity,impact
df_clean = df_clean[, -c(1, 2, 24)]
df_clean=df_clean[complete.cases(df_clean),]
#split 2020 and before 
yr2020 <- df_clean$Year == '2020'
df20 <- df_clean[yr2020, ]
df_old <- df_clean[!yr2020, ]
```


```{r}
#remove start latitude and start longitude (remove state for now, because too many levels); Remove Year 
car20_mat <- model.matrix(duration~., df20[, -c(1, 2, 4, 18)])
car20_mat <- car20_mat[,2:ncol(car20_mat)]
carold_mat <- model.matrix(duration~., df_old[, -c(1, 2, 4, 18)])
carold_mat <- carold_mat[,2:ncol(carold_mat)]

set.seed(1)

index <- sample(1:nrow(df20), floor(0.2*nrow(df20)), replace = FALSE)
train20_x <- car20_mat[-index,]
train20_y <- df20$duration[-index]
test20_x <- car20_mat[index,] 
test20_y <- df20$duration[index]

index2 <- sample(1:nrow(df_old), floor(0.2*nrow(df_old)), replace = FALSE)
trainold_x <- carold_mat[-index2,]
trainold_y <- df_old$duration[-index2]
testold_x <- carold_mat[index2,] 
testold_y <- df_old$duration[index2]

##Random shuffle 
inds <- sample(1:nrow(train20_x), nrow(train20_x), replace=FALSE)
train20_x <- train20_x[inds, ]
train20_y <- train20_y[inds]

inds2 <- sample(1:nrow(trainold_x), nrow(trainold_x), replace=FALSE)
trainold_x <- trainold_x[inds2, ]
trainold_y <- trainold_y[inds2]

```


```{r}
# Scale x
train20_means <- apply(train20_x, 2, mean)
train20_sds <- apply(train20_x, 2, sd)
train20_x <- sweep(sweep(train20_x, 2L, train20_means), 2, train20_sds, "/")
test20_x <- sweep(sweep(test20_x, 2L, train20_means), 2, train20_sds, "/")

trainold_means <- apply(trainold_x, 2, mean)
trainold_sds <- apply(trainold_x, 2, sd)
trainold_x <- sweep(sweep(trainold_x, 2L, trainold_means), 2, trainold_sds, "/")
testold_x <- sweep(sweep(testold_x, 2L, trainold_means), 2, trainold_sds, "/")

##Scale y 


train20_ymeans <- mean(train20_y)
train20_ysds <- sd(train20_y)
train20_y <- scale(train20_y, center = train20_ymeans, scale = train20_ysds)
test20_y <- scale(test20_y, center = train20_ymeans, scale = train20_ysds)

trainold_ymeans <- mean(trainold_y)
trainold_ysds <- sd(trainold_y)
trainold_y <- scale(trainold_y, center = trainold_ymeans, scale = trainold_ysds)
testold_y <- scale(testold_y, center = trainold_ymeans, scale = trainold_ysds)
```


### First model 
```{r}
# Create network architecture with dropout
set.seed(1)
model1 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
summary(model1) 

model1 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history0_20 <- model1%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2,
    shuffle = TRUE
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
plot(history0_20)+ labs(title = 'Initial model on 2020 dataset')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```

```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y_scaled = predict(model1, test20_x)
pred20_y = pred_y_scaled*train20_ysds+train20_ymeans
test20_y_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y-test20_y_ori)^2)))
## RMSE is 51.45                   , while the RF's RMSE is 51.65

```

### increase batch size 

```{r}
# Create network architecture with dropout
set.seed(1)
model1 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model1) 

model1 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history1_20 <- model1%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2,
    shuffle = TRUE,
    batch_size = 100
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
plot(history1_20)+ labs(title = 'Initial model on 2020 dataset with batch size 100')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```


```{r}
# Create network architecture with dropout
set.seed(1)
model1 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model1) 

model1 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history1.1_20 <- model1%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2,
    batch_size= 200
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
plot(history1.1_20)+ labs(title = 'Initial model on 2020 dataset (batch size: 200)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```


```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y_scaled = predict(model1, test20_x)
pred20_y1 = pred_y_scaled*train20_ysds+train20_ymeans
test20_y_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y1-test20_y_ori)^2)))
## RMSE is 51.47, while the RF's RMSE is 51.65

```





```{r}
set.seed(1)
## add one more layer
model2 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
summary(model2) 

model2 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history2.1_20 <- model2%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    shuffle = T,
    batch_size = 200
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
plot(history2.1_20)+ labs(title = '4 layer model on 2020 dataset(batch size: 200)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```


```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y2_scaled = predict(model2, test20_x)
pred20_y2 = pred_y2_scaled*train20_ysds+train20_ymeans
test20_y2_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y2-test20_y2_ori)^2)))
## RMSE is 51.33, while the RF's RMSE is 51.65

```

Saw some over fitting in 2 hidden layer model. May be start to add regularization to the model 



```{r}
set.seed(1)
## add one more layer
model2<- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model2) 

model2 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)

set.seed(1)
history2.2_20 <- model2%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200,
    shuffle = T,
    callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
model2%>%evaluate(test20_x, test20_y, verbose = 0) ## test mse 0.677
```

```{r}
history2.2_20$params$epochs = length(history2.2_20$metrics$loss)
plot(history2.2_20)+labs(title = '4 layer model on 2020 dataset(early stop)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```

```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y_scaled = predict(model2, test20_x)
pred20_y = pred_y_scaled*train20_ysds+train20_ymeans
test20_y_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y-test20_y_ori)^2)))
## RMSE is 51.48, while the RF's RMSE is 51.65
```

```{r}
set.seed(1)
## add one dropout rate0.5
model2.1<- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model2) 

model2.1 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)

set.seed(1)
history2.3_20 <- model2.1%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200,
    shuffle = T,
    callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
model2.1%>%evaluate(test20_x, test20_y, verbose = 0) ## test mse 0.745
```

```{r}
set.seed(1)
## add l1
model2.2<- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x),regularizer_l1(l = 0.01)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model2) 

model2.2 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)

set.seed(1)
history2.4_20 <- model2.2%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200,
    shuffle = T
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
model2.2%>%evaluate(test20_x, test20_y, verbose = 0) ## test mse 0.745
```

```{r}
#history2.2_20$params$epochs = length(history2.2_20$metrics$loss)
plot(history2.4_20)+labs(title = '4 layer model on 2020 dataset(l1 = 0.01)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```

```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y_scaled = predict(model2.2, test20_x)
pred20_y = pred_y_scaled*train20_ysds+train20_ymeans
test20_y_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y-test20_y_ori)^2)))
## RMSE is 51.34, while the RF's RMSE is 51.65

```

```{r}
set.seed(1)
## add l1
model2.3<- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x),regularizer_l1(l = 0.01)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu", regularizer_l1(l = 0.01)) %>%
  layer_dense(units = ncol(train20_x), activation = "relu", regularizer_l1(l = 0.01)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear", regularizer_l1(l = 0.01))
#summary(model2) 

model2.3 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)

set.seed(1)
history2.5_20 <- model2.3%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200,
    shuffle = T
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
model2.3%>%evaluate(test20_x, test20_y, verbose = 0) ## test mse 0.670
```

```{r}
#history2.2_20$params$epochs = length(history2.2_20$metrics$loss)
plot(history2.5_20)+labs(title = '4 layer model on 2020 dataset(l1 = 0.01 all layers)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```


```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y_scaled = predict(model2.3, test20_x)
pred20_y = pred_y_scaled*train20_ysds+train20_ymeans
test20_y_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y-test20_y_ori)^2)))
## RMSE is 51.20, while the RF's RMSE is 51.65

```

```{r}
set.seed(1)
## add l1
model2.3<- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x),regularizer_l1(l = 0.01)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu", regularizer_l1(l = 0.01)) %>%
  layer_dense(units = ncol(train20_x), activation = "relu", regularizer_l1(l = 0.01)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear", regularizer_l1(l = 0.01))
#summary(model2) 

model2.3 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)

set.seed(1)
history2.5.1_20 <- model2.3%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200,
    shuffle = T,
    callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
model2.3%>%evaluate(test20_x, test20_y, verbose = 0) ## test mse 0.670
```

```{r}
history2.5.1_20$params$epochs = length(history2.5.1_20$metrics$loss)
plot(history2.5.1_20)+labs(title = '4 layer model on 2020 dataset(l1 = 0.01 all layers +early stop)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```


```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y_scaled = predict(model2.3, test20_x)
pred20_y = pred_y_scaled*train20_ysds+train20_ymeans
test20_y_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y-test20_y_ori)^2)))
## RMSE is 51.62, while the RF's RMSE is 51.65

```


## Model with 3 hidden layers

```{r}
set.seed(1)
## add one more layer
model3 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
summary(model3) 

model3 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history3.1_20 <- model3%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200, 
    shuffle = T
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
plot(history3.1_20)+labs(title = '5 layer model on 2020 dataset(batch size: 200)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```

```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y3_scaled = predict(model3, test20_x)
pred20_y3 = pred_y3_scaled*train20_ysds+train20_ymeans
test20_y3_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y3-test20_y3_ori)^2)))
## RMSE is 51.19, while the RF's RMSE is 51.65

```


```{r}
set.seed(1)
## add one more layer
model3 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model3) 

model3 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history3.2_20 <- model3%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200, 
    shuffle = T,
    callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
history3.2_20$params$epochs = length(history3.2_20$metrics$loss)
plot(history3.2_20)+labs(title = '5 layer model on 2020 dataset(with early stop)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```


```{r}
model3%>%evaluate(test20_x, test20_y, verbose = 0)

pred_y_scaled = predict(model3, test20_x)
pred20_y = pred_y_scaled*train20_ysds+train20_ymeans
test20_y_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y-test20_y_ori)^2)))
## RMSE is 51.5, while the RF's RMSE is 51.65
```

```{r}
set.seed(1)
## add one more layer
model3.1 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model3) 

model3.1 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history3.3_20 <- model3.1%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200, 
    shuffle = T,
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
#history3.3_20$params$epochs = length(history3.3_20$metrics$loss)
plot(history3.3_20)+labs(title = '5 layer model on 2020 dataset(with 2 dropout)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))

model3.1%>%evaluate(test20_x, test20_y, verbose = 0)
```

```{r}
set.seed(1)
## add one more layer
model3.2 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = 1, activation = "linear")
#summary(model3) 

model3.2 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history3.4_20 <- model3.2%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200, 
    shuffle = T,
    callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
history3.4_20$params$epochs = length(history3.4_20$metrics$loss)
plot(history3.4_20)+labs(title = '5 layer model on 2020 dataset(with 1 dropout+early stop)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))

model3.2%>%evaluate(test20_x, test20_y, verbose = 0)
```


```{r}
set.seed(1)
## add one more layer
model3.3 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  layer_dropout(rate = 0.2)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = 1, activation = "linear")
#summary(model3) 

model3.3 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history3.5_20 <- model3.3%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200, 
    shuffle = T
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
#history3.4_20$params$epochs = length(history3.4_20$metrics$loss)
plot(history3.5_20)+labs(title = '5 layer model on 2020 dataset(with 1 dropout (0.2))')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))

model3.3%>%evaluate(test20_x, test20_y, verbose = 0)
```

```{r}
pred_y_scaled = predict(model3.3, test20_x)
pred20_y = pred_y_scaled*train20_ysds+train20_ymeans
test20_y_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y-test20_y_ori)^2)))
## test RMSE is 51.88
```



```{r}
# add early stop but it stopped too early 
set.seed(1)
history3.6_20 <- model3.3%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200, 
    shuffle = T,
    callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```


## Model with 4 hidden layers

```{r}
set.seed(1)
## add one more layer
model4 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
summary(model4) 

model4 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history4.1_20 <- model4%>%  
  fit(
    x = train20_x,
    y = train20_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200, 
    shuffle = T
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

```{r}
plot(history4.1_20)+labs(title = '6 layer model on 2020 dataset(batch size: 200)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```

```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y4_scaled = predict(model4, test20_x)
pred20_y4 = pred_y4_scaled*train20_ysds+train20_ymeans
test20_y4_ori = test20_y*train20_ysds+train20_ymeans

cat('RMSE of the test set is ',sqrt(mean((pred20_y4-test20_y4_ori)^2)))
## RMSE is 51.25, while the RF's RMSE is 51.65

```


Fit the 3 layer model on old data (2016-2019) set
```{r}
# Create network architecture with dropout
set.seed(1)
model1 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model1) 

model1 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)
```

```{r}
set.seed(1)
history1_old <- model1%>%  
  fit(
    x = trainold_x,
    y = trainold_y,
    epochs = 100,
    validation_split = 0.2, 
    shuffle = T, 
    batch_size = 200
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

Train loss: 0.682, Val loss 0.673

```{r}
## validation mse and val mse look like two parallel lines. May be the model is not learning. 
## modify the model add more layers?
plot(history1_old)+ labs(title = 'Initial model on old dataset (batch size : 200)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```

```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y_scaled1 = predict(model1, testold_x)
predold_y1 = pred_y_scaled1*trainold_ysds+trainold_ymeans
testold_y_ori1 = testold_y*trainold_ysds+trainold_ymeans

cat('RMSE of the test set is ',sqrt(mean((predold_y1-testold_y_ori1)^2)))
  ## last old RF RMSE is 35.1, this is 34.73
```


Fit 2nd  on old dataset
```{r}
set.seed(1)
## add one dropout rate0.5
model2<- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model2) 

model2 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)

set.seed(1)
history2.1_old <- model2%>%  
  fit(
    x = trainold_x,
    y = trainold_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200,
    shuffle = T,
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

Final val loss: 0.664, train loss: 0.667

```{r}
## validation mse and val mse look like two parallel lines. May be the model is not learning. 
## modify the model add more layers?
plot(history2.1_old)+ labs(title = '4 layer model on old dataset (batch size : 200)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```

```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y_scaled2 = predict(model2, testold_x)
predold_y2 = pred_y_scaled2*trainold_ysds+trainold_ymeans
testold_y_ori2 = testold_y*trainold_ysds+trainold_ymeans

cat('RMSE of the test set is ',sqrt(mean((predold_y2-testold_y_ori2)^2)))
  ## last old RF RMSE is 35.1, this is 34.47
```

Early stop may help in this model 

```{r}
set.seed(1)
## add one dropout rate0.5
model2<- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model2) 

model2 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)

set.seed(1)
history2.2_old <- model2%>%  
  fit(
    x = trainold_x,
    y = trainold_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200,
    shuffle = T,
    callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```


Stop at train loss: 0.680, val loss:0.673

```{r}
## validation mse and val mse look like two parallel lines. May be the model is not learning. 
## modify the model add more layers?
history2.2_old$params$epochs = length(history2.2_old$metrics$loss)
plot(history2.2_old)+ labs(title = '4 layer model on old dataset (batch size : 200, early stop)')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```

```{r}
## Calculate RMSE from the prediction 
## since X and y are both scaled, need to convert y back by multiply sd and add mean 
pred_y_scaled2 = predict(model2, testold_x)
predold_y2 = pred_y_scaled2*trainold_ysds+trainold_ymeans
testold_y_ori2 = testold_y*trainold_ysds+trainold_ymeans

cat('RMSE of the test set is ',sqrt(mean((predold_y2-testold_y_ori2)^2)))
  ## last old RF RMSE is 35.1, this is 34.68
```

```{r}
set.seed(1)
## add one more layer
model3 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model3) 

model3 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)

set.seed(1)
history3.1_old <- model3%>%  
  fit(
    x = trainold_x,
    y = trainold_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200, 
    shuffle = T,
    #callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

Train loss = 0.663, validation loss is 0.661
```{r}
#history3.2_20$params$epochs = length(history3.2_20$metrics$loss)
plot(history3.1_old)+labs(title = '5 layer model on old dataset')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```


```{r}
model3%>%evaluate(testold_x, testold_y, verbose = 0)

pred_y_scaled = predict(model3, testold_x)
predold_y = pred_y_scaled*trainold_ysds+trainold_ymeans
testold_y_ori = testold_y*trainold_ysds+trainold_ymeans

cat('RMSE of the test set is ',sqrt(mean((predold_y-testold_y_ori)^2)))
## RMSE is 34.39, RF: 35.1
```

```{r}
set.seed(1)
## add one more layer
model3 <- keras_model_sequential() %>%
  # start with units the same as the number of columns
  layer_dense(units = ncol(train20_x), activation = "relu", input_shape = ncol(train20_x)) %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  layer_dense(units = ncol(train20_x), activation = "relu") %>%
  #layer_dropout(rate = 0.5)%>%
  layer_dense(units = 1, activation = "linear")
#summary(model3) 

model3 %>% compile(
  optimizer = 'adam', 
  loss = 'mse',
  metrics ='mse'
)

set.seed(1)
history3.2_old <- model3%>%  
  fit(
    x = trainold_x,
    y = trainold_y,
    epochs = 100,
    validation_split = 0.2, 
    batch_size = 200, 
    shuffle = T,
    callbacks = callback_early_stopping(monitor="val_loss", patience = 4) #look at validation loss to early stop the model
  )
```

Train loss = 0.663, validation loss is 0.661
```{r}
history3.2_old$params$epochs = length(history3.2_old$metrics$loss)
plot(history3.2_old)+labs(title = '5 layer model on old dataset')+theme_classic()+theme(plot.title = element_text(hjust = 0.5))
```


```{r}
model3%>%evaluate(testold_x, testold_y, verbose = 0)

pred_y_scaled = predict(model3, testold_x)
predold_y = pred_y_scaled*trainold_ysds+trainold_ymeans
testold_y_ori = testold_y*trainold_ysds+trainold_ymeans

cat('RMSE of the test set is ',sqrt(mean((predold_y-testold_y_ori)^2)))
## RMSE is 34.8, RF: 35.1
```
